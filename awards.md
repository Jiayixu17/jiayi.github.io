---
layout: page
permalink: /awards/index.html
title: Research
---
## Research Experience
<em>**China University of Geosciences - Center for International Cooperation in E-Business** (Mar 2021 - Present)</em>      
<em>Research Assistant|Advisor: [Prof. Zhen Zhu](https://grzy.cug.edu.cn/zhuzhen/zh_CN/index.htm) </em> <br>

**Project: Knowledge Graph Construction and Attribute Value Extraction for Large-scale Textual Data of Tourism Products**      
- Used Python to crawl and preprocess product textual data from Ctrip.com.
- Constructed a domain ontology for tourism products, incorporating 9 feature dimensions.
- Extracted tourism product features using BERT-BiLSTM-CRF and merged entities with highly semantic similarity.
- Imported entities and relations into a Neo4j database for graph visualization.
- Obtained product similarity through link prediction algorithms (Adamic-Adar) and modified cosine similarity.    
<br>

**<em>Project: Research on Product Homogeneity Characteristics and Performance of Complementors in E-commerce Platforms</em>**
- Measured the homogeneity level of products between platform owner and complementors by constructing graph networks and calculating graph node similarity.
- Introduced 42 additional feature variables for the complementors and trained the sales forecasting model using XGBoost.
- Generated parameter interpretation by SHAP feature importance derived from the XGBoost model.
- Devised the plan to use causal inference methods to facilitate the interpretation of treatment variables.
<br>

**Tongji University** (Apr 2022 - Sept 2022)<br> 
<em>Research Intern | Advisor: [Prof. Changrong Lu](https://www.linkedin.com/in/drchangronglu/?locale=en_US)</em>
- Compiled journal articles related to geopolitical risks in the past 20 years based on TF-IDF and counted the distribution of the number of articles by year.
- Measured the similarity between datasets using Pearson's correlation coefficient, cosine similarity, and KL divergence.
- Implemented term set expansion, including training word embedding mode (Word2vec), manual annotations, and building classification models using Random Forest.
<br>

